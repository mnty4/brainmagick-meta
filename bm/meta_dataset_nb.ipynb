{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hostname lukas-B550-AORUS-ELITE-AX-V2 not defined in /conf/study_paths/study_paths.yaml. Using default paths.\n",
      "/home/lukas/anaconda3/envs/brainmagick/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lukas/projects/brainmagick\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hostname lukas-B550-AORUS-ELITE-AX-V2 not defined in /conf/study_paths/study_paths.yaml. Using default paths.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello there good sir.\n",
      "Opening raw data file /home/lukas/projects/brainmagick/cache/studies/gwilliams2022/01_session0_story0/meg-sr120-hp0-raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 0 ... 47519 =      0.000 ...   395.992 secs\n",
      "Ready.\n",
      "Opening raw data file /home/lukas/projects/brainmagick/cache/studies/gwilliams2022/01_session0_story1/meg-sr120-hp0-raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 0 ... 85919 =      0.000 ...   715.992 secs\n",
      "Ready.\n",
      "Opening raw data file /home/lukas/projects/brainmagick/cache/studies/gwilliams2022/01_session0_story2/meg-sr120-hp0-raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 0 ... 143039 =      0.000 ...  1191.992 secs\n",
      "Ready.\n",
      "Opening raw data file /home/lukas/projects/brainmagick/cache/studies/gwilliams2022/01_session0_story3/meg-sr120-hp0-raw.fif...\n",
      "Isotrak not found\n",
      "    Range : 0 ... 224279 =      0.000 ...  1868.992 secs\n",
      "Ready.\n",
      "[Gwilliams2022Recording('01_session0_story0'), Gwilliams2022Recording('01_session0_story1'), Gwilliams2022Recording('01_session0_story2'), Gwilliams2022Recording('01_session0_story3')]\n",
      "Extracting SQD Parameters from /home/lukas/projects/brainmagick/data/gwilliams2022/download/sub-01/ses-0/meg/sub-01_ses-0_task-0_meg.con...\n",
      "Creating Raw.info structure...\n",
      "Setting channel info structure...\n",
      "Creating Info structure...\n",
      "Ready.\n",
      "Reading events from /home/lukas/projects/brainmagick/data/gwilliams2022/download/sub-01/ses-0/meg/sub-01_ses-0_task-0_events.tsv.\n",
      "Reading channel info from /home/lukas/projects/brainmagick/data/gwilliams2022/download/sub-01/ses-0/meg/sub-01_ses-0_task-0_channels.tsv.\n",
      "The stimulus channel \"STI 014\" is present in the raw data, but not included in channels.tsv. Removing the channel.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Extracting SQD Parameters from /home/lukas/projects/brainmagick/data/gwilliams2022/download/sub-01/ses-0/meg/sub-01_ses-0_task-1_meg.con...\n",
      "Creating Raw.info structure...\n",
      "Setting channel info structure...\n",
      "Creating Info structure...\n",
      "Ready.\n",
      "Reading events from /home/lukas/projects/brainmagick/data/gwilliams2022/download/sub-01/ses-0/meg/sub-01_ses-0_task-1_events.tsv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukas/projects/brainmagick/bm/studies/gwilliams2022.py:106: RuntimeWarning: The unit for channel(s) MISC 001, MISC 002, MISC 003, MISC 004, MISC 005, MISC 006, MISC 007, MISC 008, MISC 009, MISC 010, MISC 011, MISC 012, MISC 013, MISC 014, MISC 015, MISC 016, MISC 017, MISC 018, MISC 019, MISC 020, MISC 021, MISC 022, MISC 023, MISC 024, MISC 025, MISC 026, MISC 027, MISC 028, MISC 029, MISC 030, MISC 031, MISC 032 has changed from V to NA.\n",
      "  raw = read_raw_bids(bids_path)  # FIXME this is NOT a lazy read\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading channel info from /home/lukas/projects/brainmagick/data/gwilliams2022/download/sub-01/ses-0/meg/sub-01_ses-0_task-1_channels.tsv.\n",
      "The stimulus channel \"STI 014\" is present in the raw data, but not included in channels.tsv. Removing the channel.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Extracting SQD Parameters from /home/lukas/projects/brainmagick/data/gwilliams2022/download/sub-01/ses-0/meg/sub-01_ses-0_task-2_meg.con...\n",
      "Creating Raw.info structure...\n",
      "Setting channel info structure...\n",
      "Creating Info structure...\n",
      "Ready.\n",
      "Reading events from /home/lukas/projects/brainmagick/data/gwilliams2022/download/sub-01/ses-0/meg/sub-01_ses-0_task-2_events.tsv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukas/projects/brainmagick/bm/studies/gwilliams2022.py:106: RuntimeWarning: The unit for channel(s) MISC 001, MISC 002, MISC 003, MISC 004, MISC 005, MISC 006, MISC 007, MISC 008, MISC 009, MISC 010, MISC 011, MISC 012, MISC 013, MISC 014, MISC 015, MISC 016, MISC 017, MISC 018, MISC 019, MISC 020, MISC 021, MISC 022, MISC 023, MISC 024, MISC 025, MISC 026, MISC 027, MISC 028, MISC 029, MISC 030, MISC 031, MISC 032 has changed from V to NA.\n",
      "  raw = read_raw_bids(bids_path)  # FIXME this is NOT a lazy read\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading channel info from /home/lukas/projects/brainmagick/data/gwilliams2022/download/sub-01/ses-0/meg/sub-01_ses-0_task-2_channels.tsv.\n",
      "The stimulus channel \"STI 014\" is present in the raw data, but not included in channels.tsv. Removing the channel.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Extracting SQD Parameters from /home/lukas/projects/brainmagick/data/gwilliams2022/download/sub-01/ses-0/meg/sub-01_ses-0_task-3_meg.con...\n",
      "Creating Raw.info structure...\n",
      "Setting channel info structure...\n",
      "Creating Info structure...\n",
      "Ready.\n",
      "Reading events from /home/lukas/projects/brainmagick/data/gwilliams2022/download/sub-01/ses-0/meg/sub-01_ses-0_task-3_events.tsv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukas/projects/brainmagick/bm/studies/gwilliams2022.py:106: RuntimeWarning: The unit for channel(s) MISC 001, MISC 002, MISC 003, MISC 004, MISC 005, MISC 006, MISC 007, MISC 008, MISC 009, MISC 010, MISC 011, MISC 012, MISC 013, MISC 014, MISC 015, MISC 016, MISC 017, MISC 018, MISC 019, MISC 020, MISC 021, MISC 022, MISC 023, MISC 024, MISC 025, MISC 026, MISC 027, MISC 028, MISC 029, MISC 030, MISC 031, MISC 032 has changed from V to NA.\n",
      "  raw = read_raw_bids(bids_path)  # FIXME this is NOT a lazy read\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading channel info from /home/lukas/projects/brainmagick/data/gwilliams2022/download/sub-01/ses-0/meg/sub-01_ses-0_task-3_channels.tsv.\n",
      "The stimulus channel \"STI 014\" is present in the raw data, but not included in channels.tsv. Removing the channel.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Extracting SQD Parameters from /home/lukas/projects/brainmagick/data/gwilliams2022/download/sub-01/ses-0/meg/sub-01_ses-0_task-0_meg.con...\n",
      "Creating Raw.info structure...\n",
      "Setting channel info structure...\n",
      "Creating Info structure...\n",
      "Ready.\n",
      "Reading events from /home/lukas/projects/brainmagick/data/gwilliams2022/download/sub-01/ses-0/meg/sub-01_ses-0_task-0_events.tsv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukas/projects/brainmagick/bm/studies/gwilliams2022.py:106: RuntimeWarning: The unit for channel(s) MISC 001, MISC 002, MISC 003, MISC 004, MISC 005, MISC 006, MISC 007, MISC 008, MISC 009, MISC 010, MISC 011, MISC 012, MISC 013, MISC 014, MISC 015, MISC 016, MISC 017, MISC 018, MISC 019, MISC 020, MISC 021, MISC 022, MISC 023, MISC 024, MISC 025, MISC 026, MISC 027, MISC 028, MISC 029, MISC 030, MISC 031, MISC 032 has changed from V to NA.\n",
      "  raw = read_raw_bids(bids_path)  # FIXME this is NOT a lazy read\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading channel info from /home/lukas/projects/brainmagick/data/gwilliams2022/download/sub-01/ses-0/meg/sub-01_ses-0_task-0_channels.tsv.\n",
      "The stimulus channel \"STI 014\" is present in the raw data, but not included in channels.tsv. Removing the channel.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukas/projects/brainmagick/bm/studies/gwilliams2022.py:106: RuntimeWarning: The unit for channel(s) MISC 001, MISC 002, MISC 003, MISC 004, MISC 005, MISC 006, MISC 007, MISC 008, MISC 009, MISC 010, MISC 011, MISC 012, MISC 013, MISC 014, MISC 015, MISC 016, MISC 017, MISC 018, MISC 019, MISC 020, MISC 021, MISC 022, MISC 023, MISC 024, MISC 025, MISC 026, MISC 027, MISC 028, MISC 029, MISC 030, MISC 031, MISC 032 has changed from V to NA.\n",
      "  raw = read_raw_bids(bids_path)  # FIXME this is NOT a lazy read\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting SQD Parameters from /home/lukas/projects/brainmagick/data/gwilliams2022/download/sub-01/ses-0/meg/sub-01_ses-0_task-1_meg.con...\n",
      "Creating Raw.info structure...\n",
      "Setting channel info structure...\n",
      "Creating Info structure...\n",
      "Ready.\n",
      "Reading events from /home/lukas/projects/brainmagick/data/gwilliams2022/download/sub-01/ses-0/meg/sub-01_ses-0_task-1_events.tsv.\n",
      "Reading channel info from /home/lukas/projects/brainmagick/data/gwilliams2022/download/sub-01/ses-0/meg/sub-01_ses-0_task-1_channels.tsv.\n",
      "The stimulus channel \"STI 014\" is present in the raw data, but not included in channels.tsv. Removing the channel.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukas/projects/brainmagick/bm/studies/gwilliams2022.py:106: RuntimeWarning: The unit for channel(s) MISC 001, MISC 002, MISC 003, MISC 004, MISC 005, MISC 006, MISC 007, MISC 008, MISC 009, MISC 010, MISC 011, MISC 012, MISC 013, MISC 014, MISC 015, MISC 016, MISC 017, MISC 018, MISC 019, MISC 020, MISC 021, MISC 022, MISC 023, MISC 024, MISC 025, MISC 026, MISC 027, MISC 028, MISC 029, MISC 030, MISC 031, MISC 032 has changed from V to NA.\n",
      "  raw = read_raw_bids(bids_path)  # FIXME this is NOT a lazy read\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting SQD Parameters from /home/lukas/projects/brainmagick/data/gwilliams2022/download/sub-01/ses-0/meg/sub-01_ses-0_task-2_meg.con...\n",
      "Creating Raw.info structure...\n",
      "Setting channel info structure...\n",
      "Creating Info structure...\n",
      "Ready.\n",
      "Reading events from /home/lukas/projects/brainmagick/data/gwilliams2022/download/sub-01/ses-0/meg/sub-01_ses-0_task-2_events.tsv.\n",
      "Reading channel info from /home/lukas/projects/brainmagick/data/gwilliams2022/download/sub-01/ses-0/meg/sub-01_ses-0_task-2_channels.tsv.\n",
      "The stimulus channel \"STI 014\" is present in the raw data, but not included in channels.tsv. Removing the channel.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukas/projects/brainmagick/bm/studies/gwilliams2022.py:106: RuntimeWarning: The unit for channel(s) MISC 001, MISC 002, MISC 003, MISC 004, MISC 005, MISC 006, MISC 007, MISC 008, MISC 009, MISC 010, MISC 011, MISC 012, MISC 013, MISC 014, MISC 015, MISC 016, MISC 017, MISC 018, MISC 019, MISC 020, MISC 021, MISC 022, MISC 023, MISC 024, MISC 025, MISC 026, MISC 027, MISC 028, MISC 029, MISC 030, MISC 031, MISC 032 has changed from V to NA.\n",
      "  raw = read_raw_bids(bids_path)  # FIXME this is NOT a lazy read\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting SQD Parameters from /home/lukas/projects/brainmagick/data/gwilliams2022/download/sub-01/ses-0/meg/sub-01_ses-0_task-3_meg.con...\n",
      "Creating Raw.info structure...\n",
      "Setting channel info structure...\n",
      "Creating Info structure...\n",
      "Ready.\n",
      "Reading events from /home/lukas/projects/brainmagick/data/gwilliams2022/download/sub-01/ses-0/meg/sub-01_ses-0_task-3_events.tsv.\n",
      "Reading channel info from /home/lukas/projects/brainmagick/data/gwilliams2022/download/sub-01/ses-0/meg/sub-01_ses-0_task-3_channels.tsv.\n",
      "The stimulus channel \"STI 014\" is present in the raw data, but not included in channels.tsv. Removing the channel.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukas/projects/brainmagick/bm/studies/gwilliams2022.py:106: RuntimeWarning: The unit for channel(s) MISC 001, MISC 002, MISC 003, MISC 004, MISC 005, MISC 006, MISC 007, MISC 008, MISC 009, MISC 010, MISC 011, MISC 012, MISC 013, MISC 014, MISC 015, MISC 016, MISC 017, MISC 018, MISC 019, MISC 020, MISC 021, MISC 022, MISC 023, MISC 024, MISC 025, MISC 026, MISC 027, MISC 028, MISC 029, MISC 030, MISC 031, MISC 032 has changed from V to NA.\n",
      "  raw = read_raw_bids(bids_path)  # FIXME this is NOT a lazy read\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3172 entries, 0 to 3171\n",
      "Data columns (total 22 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   story          3134 non-null   object \n",
      " 1   story_uid      3134 non-null   float64\n",
      " 2   sound_id       3134 non-null   float64\n",
      " 3   kind           3172 non-null   object \n",
      " 4   start          3172 non-null   float64\n",
      " 5   sound          3134 non-null   object \n",
      " 6   duration       3172 non-null   float64\n",
      " 7   filepath       4 non-null      object \n",
      " 8   phoneme        2462 non-null   object \n",
      " 9   sequence_id    3130 non-null   float64\n",
      " 10  condition      3130 non-null   object \n",
      " 11  word_index     3130 non-null   float64\n",
      " 12  speech_rate    3130 non-null   float64\n",
      " 13  voice          3130 non-null   object \n",
      " 14  pronounced     3130 non-null   float64\n",
      " 15  word           668 non-null    object \n",
      " 16  language       3172 non-null   object \n",
      " 17  modality       3172 non-null   object \n",
      " 18  word_sequence  668 non-null    object \n",
      " 19  phoneme_id     2462 non-null   float64\n",
      " 20  offset         4 non-null      float64\n",
      " 21  uid            38 non-null     object \n",
      "dtypes: float64(10), object(12)\n",
      "memory usage: 545.3+ KB\n"
     ]
    }
   ],
   "source": [
    "from bm import meta_dataset\n",
    "from bm import meta_preprocess\n",
    "from pathlib import Path\n",
    "import bm\n",
    "import sys\n",
    "import os\n",
    "from hydra import initialize, compose\n",
    "import hydra\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "\n",
    "sys.argv=['self.py']\n",
    "\n",
    "os.chdir(Path(bm.__file__).parent.parent)\n",
    "print(os.getcwd())\n",
    "with initialize(version_base=\"1.1\", config_path=\"conf\"):\n",
    "    cfg = compose(config_name=\"config.yaml\", overrides=['+HYDRA_FULL_ERROR=1'])\n",
    "    raws, events = meta_preprocess.main(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukas/anaconda3/envs/brainmagick/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Wav2Vec2Model, Wav2Vec2Processor\n",
    "import librosa\n",
    "\n",
    "# processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\", torch_dtype=torch.float16, attn_implementation=\"flash_attention_2\")\n",
    " # model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-large-960h-lv60-self\", torch_dtype=torch.float16, attn_implementation=\"flash_attention_2\", output_hidden_states=True).to(device)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\").to(device)\n",
    "\n",
    "\n",
    "def get_audio_label(wav_path, start, duration):\n",
    "    data_dir = Path('data/gwilliams2022/download')\n",
    "    audio, rate = librosa.load(os.path.join(data_dir, wav_path), sr = 16000, offset=start, duration=duration)\n",
    "    \n",
    "    # Process the audio to extract input features\n",
    "    input_features = processor(audio, sampling_rate=16000, return_tensors=\"pt\").input_values.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_features)\n",
    "\n",
    "    audio_embeddings = outputs.last_hidden_state\n",
    "    return audio_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukas/anaconda3/envs/brainmagick/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from bm import speech_embeddings\n",
    "\n",
    "generate_embeddings = speech_embeddings.SpeechEmbeddings(**cfg)\n",
    "\n",
    "def get_audio_label(*args, **kwargs):\n",
    "    return generate_embeddings.get_audio_embeddings(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lukas/projects/brainmagick\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3134 entries, 0 to 3133\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   onset        3134 non-null   datetime64[ns]\n",
      " 1   duration     3134 non-null   float64       \n",
      " 2   description  3134 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(1), object(1)\n",
      "memory usage: 73.6+ KB\n",
      "1\n",
      "Effective window size : 0.301 (s)\n",
      "Tara tensor([[-0.0872,  0.1290, -0.0086,  ...,  0.0599,  0.0710,  0.0133],\n",
      "        [-0.0077,  0.2152,  0.1333,  ..., -0.0731, -0.0028, -0.0153],\n",
      "        [-0.0583,  0.1397,  0.0592,  ..., -0.0716, -0.0791, -0.0359],\n",
      "        ...,\n",
      "        [-0.0486,  0.0982,  0.1229,  ..., -0.0835, -0.1260,  0.0292],\n",
      "        [-0.0637,  0.0231,  0.1398,  ...,  0.0545, -0.0449, -0.0913],\n",
      "        [ 0.0319,  0.0197,  0.1984,  ...,  0.3208, -0.0074, -0.2722]],\n",
      "       device='cuda:0') torch.Size([0])\n",
      "7\n",
      "Effective window size : 0.241 (s)\n",
      "stood tensor([[-0.0271,  0.1760,  0.1068,  ..., -0.0485,  0.0596,  0.0204],\n",
      "        [-0.0549,  0.2094,  0.2073,  ...,  0.0646,  0.0913,  0.0020],\n",
      "        [-0.0224,  0.2102,  0.2207,  ...,  0.0698,  0.0157, -0.0035],\n",
      "        ...,\n",
      "        [ 0.0146,  0.1082,  0.0562,  ..., -0.0476,  0.0410, -0.0164],\n",
      "        [-0.0124,  0.0534, -0.0598,  ...,  0.1371, -0.0385,  0.0534],\n",
      "        [-0.0303,  0.1370,  0.0163,  ...,  0.0702,  0.1256,  0.0469]],\n",
      "       device='cuda:0') torch.Size([1, 208, 19])\n",
      "13\n",
      "Effective window size : 0.371 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_77163/4140352302.py:63: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1724789259345/work/torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  print(word_label, audio_label, torch.tensor(x).shape)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 19 at dim 2 (got 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 63\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# preprocessed_data = to_spectrum(data)\u001b[39;00m\n\u001b[1;32m     62\u001b[0m audio_label \u001b[38;5;241m=\u001b[39m get_audio_label(wav_path, start, duration)\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28mprint\u001b[39m(word_label, audio_label, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     64\u001b[0m x\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[1;32m     65\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(audio_label)\n",
      "\u001b[0;31mValueError\u001b[0m: expected sequence of length 19 at dim 2 (got 15)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from mne.io import Raw\n",
    "import json\n",
    "\n",
    "# events[1][events[1][\"kind\"] == 'word']\n",
    "\n",
    "# print(raws[0].annotations[-1])\n",
    "\n",
    "# print(raws[0][:,52.12:])\n",
    "\n",
    "# raw = raws[0]\n",
    "# event = events[0][events[0][\"kind\"] == 'word']\n",
    "# word_event = event.iloc[0]\n",
    "# start = word_event['start']\n",
    "# end = start + word_event['duration']\n",
    "# print(start, end)\n",
    "# t_idx = raw.time_as_index([start, end])\n",
    "# data, times = raw[:,t_idx[0]:t_idx[1]]\n",
    "# print(event)\n",
    "# print(torch.tensor(data).shape)\n",
    "\n",
    "\n",
    "print(os.getcwd())\n",
    "X = []\n",
    "Y = []\n",
    "word_labels = []\n",
    "for raw, event in zip(raws, events):\n",
    "    raw: Raw\n",
    "    word_events: pd.DataFrame = event[event['kind'] == 'word']\n",
    "    raw.annotations.to_data_frame().info()\n",
    "    descs = [json.loads(desc.replace(\"'\", \"\\\"\")) for desc in raw.annotations.description]\n",
    "    starts = [desc['start'] for desc in descs if desc['kind'] == 'word']\n",
    "    x = []\n",
    "    y = []\n",
    "    w_lbs = []\n",
    "    # word_events.info()\n",
    "    for (i, word_event), start in zip(word_events.iterrows(), starts):\n",
    "        print(i)\n",
    "        if i >= 100: \n",
    "            break\n",
    "        # print(raw.annotations.description)\n",
    "        # print(raw.annotations.description[2])\n",
    "        # print(word_event)\n",
    "    \n",
    "        duration, word_label, wav_path = word_event['duration'], word_event['word'], word_event['sound'] \n",
    "\n",
    "        wav_path = wav_path.lower()\n",
    "        \n",
    "        if duration < 0.05:\n",
    "            continue\n",
    "\n",
    "        offset = 0.\n",
    "        start = start + offset\n",
    "        end = start + duration + offset\n",
    "        # print(start, end, wav_path, word_label)\n",
    "        # t_idxs = raw.time_as_index([start, end])\n",
    "        # data, times = raw[:, t_idxs[0]:t_idxs[1]] \n",
    "        data = raw.compute_psd(tmin=start, tmax=end, fmax=60)[:]\n",
    "        \n",
    "        # preprocessed_data = to_spectrum(data)\n",
    "        audio_label = get_audio_label(wav_path, start, duration)\n",
    "        print(word_label, torch.tensor(audio_label).shape, torch.tensor(data).shape)\n",
    "        x.append(data)\n",
    "        y.append(audio_label)\n",
    "        w_lbs.append(word_label)\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "    word_labels.append(w_lbs)\n",
    "\n",
    "print(X, Y, word_labels)\n",
    "\n",
    "# for each, start + offset, start + duration + offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 14, 768]) torch.Size([208, 300]) Tara\n",
      "torch.Size([1, 11, 768]) torch.Size([208, 240]) stood\n",
      "torch.Size([1, 18, 768]) torch.Size([208, 370]) stock\n",
      "torch.Size([1, 19, 768]) torch.Size([208, 400]) still\n",
      "torch.Size([1, 20, 768]) torch.Size([208, 410]) waiting\n",
      "torch.Size([1, 6, 768]) torch.Size([208, 130]) for\n",
      "torch.Size([1, 4, 768]) torch.Size([208, 90]) the\n",
      "torch.Size([1, 13, 768]) torch.Size([208, 270]) first\n",
      "torch.Size([1, 15, 768]) torch.Size([208, 310]) tiny\n",
      "torch.Size([1, 11, 768]) torch.Size([208, 240]) gleam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21450/2237729784.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  print(torch.tensor(Y[0][i]).shape, torch.tensor(X[0][i]).shape, word_labels[0][i])\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(torch.tensor(Y[0][i]).shape, torch.tensor(X[0][i]).shape, word_labels[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>story_uid</th>\n",
       "      <th>sound_id</th>\n",
       "      <th>kind</th>\n",
       "      <th>start</th>\n",
       "      <th>sound</th>\n",
       "      <th>duration</th>\n",
       "      <th>filepath</th>\n",
       "      <th>phoneme</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>...</th>\n",
       "      <th>speech_rate</th>\n",
       "      <th>voice</th>\n",
       "      <th>pronounced</th>\n",
       "      <th>word</th>\n",
       "      <th>language</th>\n",
       "      <th>modality</th>\n",
       "      <th>word_sequence</th>\n",
       "      <th>phoneme_id</th>\n",
       "      <th>offset</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>block</td>\n",
       "      <td>8.245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.120000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>english</td>\n",
       "      <td>audio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Cable Fort by Bill Glover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cable_spool_fort</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>word</td>\n",
       "      <td>8.245</td>\n",
       "      <td>stimuli/audio/cable_spool_fort_0.wav</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.0</td>\n",
       "      <td>Ava</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The</td>\n",
       "      <td>english</td>\n",
       "      <td>audio</td>\n",
       "      <td>The Cable Fort by Bill Glover</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cable_spool_fort</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sound</td>\n",
       "      <td>8.245</td>\n",
       "      <td>stimuli/audio/cable_spool_fort_0.0.wav</td>\n",
       "      <td>100.597778</td>\n",
       "      <td>/home/lukas/projects/brainmagick/data/gwilliam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>english</td>\n",
       "      <td>audio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cable_spool_fort</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>phoneme</td>\n",
       "      <td>8.245</td>\n",
       "      <td>stimuli/audio/cable_spool_fort_0.wav</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dh_B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.0</td>\n",
       "      <td>Ava</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>english</td>\n",
       "      <td>audio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cable_spool_fort</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>phoneme</td>\n",
       "      <td>8.295</td>\n",
       "      <td>stimuli/audio/cable_spool_fort_0.wav</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ah_E</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>160.0</td>\n",
       "      <td>Ava</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>english</td>\n",
       "      <td>audio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6729</th>\n",
       "      <td>cable_spool_fort</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>phoneme</td>\n",
       "      <td>700.556</td>\n",
       "      <td>stimuli/audio/cable_spool_fort_5.wav</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l_E</td>\n",
       "      <td>128.0</td>\n",
       "      <td>...</td>\n",
       "      <td>190.0</td>\n",
       "      <td>Allison</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>english</td>\n",
       "      <td>audio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6730</th>\n",
       "      <td>cable_spool_fort</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>word</td>\n",
       "      <td>700.626</td>\n",
       "      <td>stimuli/audio/cable_spool_fort_5.wav</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>128.0</td>\n",
       "      <td>...</td>\n",
       "      <td>190.0</td>\n",
       "      <td>Allison</td>\n",
       "      <td>1.0</td>\n",
       "      <td>right</td>\n",
       "      <td>english</td>\n",
       "      <td>audio</td>\n",
       "      <td>It was all right</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6731</th>\n",
       "      <td>cable_spool_fort</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>phoneme</td>\n",
       "      <td>700.626</td>\n",
       "      <td>stimuli/audio/cable_spool_fort_5.wav</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>r_B</td>\n",
       "      <td>128.0</td>\n",
       "      <td>...</td>\n",
       "      <td>190.0</td>\n",
       "      <td>Allison</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>english</td>\n",
       "      <td>audio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6732</th>\n",
       "      <td>cable_spool_fort</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>phoneme</td>\n",
       "      <td>700.716</td>\n",
       "      <td>stimuli/audio/cable_spool_fort_5.wav</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ay_I</td>\n",
       "      <td>128.0</td>\n",
       "      <td>...</td>\n",
       "      <td>190.0</td>\n",
       "      <td>Allison</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>english</td>\n",
       "      <td>audio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6733</th>\n",
       "      <td>cable_spool_fort</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>phoneme</td>\n",
       "      <td>700.856</td>\n",
       "      <td>stimuli/audio/cable_spool_fort_5.wav</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t_E</td>\n",
       "      <td>128.0</td>\n",
       "      <td>...</td>\n",
       "      <td>190.0</td>\n",
       "      <td>Allison</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>english</td>\n",
       "      <td>audio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6734 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 story  story_uid  sound_id     kind    start  \\\n",
       "0                  NaN        NaN       NaN    block    8.245   \n",
       "1     cable_spool_fort        1.0       0.0     word    8.245   \n",
       "2     cable_spool_fort        1.0       0.0    sound    8.245   \n",
       "3     cable_spool_fort        1.0       0.0  phoneme    8.245   \n",
       "4     cable_spool_fort        1.0       0.0  phoneme    8.295   \n",
       "...                ...        ...       ...      ...      ...   \n",
       "6729  cable_spool_fort        1.0       5.0  phoneme  700.556   \n",
       "6730  cable_spool_fort        1.0       5.0     word  700.626   \n",
       "6731  cable_spool_fort        1.0       5.0  phoneme  700.626   \n",
       "6732  cable_spool_fort        1.0       5.0  phoneme  700.716   \n",
       "6733  cable_spool_fort        1.0       5.0  phoneme  700.856   \n",
       "\n",
       "                                       sound    duration  \\\n",
       "0                                        NaN    3.120000   \n",
       "1       stimuli/audio/cable_spool_fort_0.wav    0.130000   \n",
       "2     stimuli/audio/cable_spool_fort_0.0.wav  100.597778   \n",
       "3       stimuli/audio/cable_spool_fort_0.wav    0.050000   \n",
       "4       stimuli/audio/cable_spool_fort_0.wav    0.080000   \n",
       "...                                      ...         ...   \n",
       "6729    stimuli/audio/cable_spool_fort_5.wav    0.070000   \n",
       "6730    stimuli/audio/cable_spool_fort_5.wav    0.430000   \n",
       "6731    stimuli/audio/cable_spool_fort_5.wav    0.090000   \n",
       "6732    stimuli/audio/cable_spool_fort_5.wav    0.140000   \n",
       "6733    stimuli/audio/cable_spool_fort_5.wav    0.200000   \n",
       "\n",
       "                                               filepath phoneme  sequence_id  \\\n",
       "0                                                   NaN     NaN          NaN   \n",
       "1                                                   NaN     NaN          0.0   \n",
       "2     /home/lukas/projects/brainmagick/data/gwilliam...     NaN          NaN   \n",
       "3                                                   NaN    dh_B          0.0   \n",
       "4                                                   NaN    ah_E          0.0   \n",
       "...                                                 ...     ...          ...   \n",
       "6729                                                NaN     l_E        128.0   \n",
       "6730                                                NaN     NaN        128.0   \n",
       "6731                                                NaN     r_B        128.0   \n",
       "6732                                                NaN    ay_I        128.0   \n",
       "6733                                                NaN     t_E        128.0   \n",
       "\n",
       "      ... speech_rate    voice  pronounced   word  language modality  \\\n",
       "0     ...         NaN      NaN         NaN    NaN   english    audio   \n",
       "1     ...       160.0      Ava         1.0    The   english    audio   \n",
       "2     ...         NaN      NaN         NaN    NaN   english    audio   \n",
       "3     ...       160.0      Ava         1.0    NaN   english    audio   \n",
       "4     ...       160.0      Ava         1.0    NaN   english    audio   \n",
       "...   ...         ...      ...         ...    ...       ...      ...   \n",
       "6729  ...       190.0  Allison         1.0    NaN   english    audio   \n",
       "6730  ...       190.0  Allison         1.0  right   english    audio   \n",
       "6731  ...       190.0  Allison         1.0    NaN   english    audio   \n",
       "6732  ...       190.0  Allison         1.0    NaN   english    audio   \n",
       "6733  ...       190.0  Allison         1.0    NaN   english    audio   \n",
       "\n",
       "                      word_sequence phoneme_id offset  \\\n",
       "0                               NaN        NaN    NaN   \n",
       "1     The Cable Fort by Bill Glover        NaN    NaN   \n",
       "2                               NaN        NaN    0.0   \n",
       "3                               NaN        0.0    NaN   \n",
       "4                               NaN        1.0    NaN   \n",
       "...                             ...        ...    ...   \n",
       "6729                            NaN        1.0    NaN   \n",
       "6730               It was all right        NaN    NaN   \n",
       "6731                            NaN        0.0    NaN   \n",
       "6732                            NaN        1.0    NaN   \n",
       "6733                            NaN        2.0    NaN   \n",
       "\n",
       "                                uid  \n",
       "0     The Cable Fort by Bill Glover  \n",
       "1                               NaN  \n",
       "2                               NaN  \n",
       "3                               NaN  \n",
       "4                               NaN  \n",
       "...                             ...  \n",
       "6729                            NaN  \n",
       "6730                            NaN  \n",
       "6731                            NaN  \n",
       "6732                            NaN  \n",
       "6733                            NaN  \n",
       "\n",
       "[6734 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hostname lukas-B550-AORUS-ELITE-AX-V2 not defined in /conf/study_paths/study_paths.yaml. Using default paths.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wandb': {'use_wandb': False, 'project': 'brainmagick', 'group': 'brainmagick-group'}, 'num_prints': 5, 'device': 'cuda', 'num_workers': 5, 'verbose': 0, 'show': 0, 'download_only': False, 'slurm': {'mem_per_gpu': 100, 'time': 4320}, 'continue_sig': None, 'continue_best': True, 'seed': 2036, 'dummy': None, 'cache': './cache', 'features_models': './features_models', 'early_stop_patience': 10, 'eval_every': 1, 'eval_train_set': False, 'optim': {'name': 'adam', 'lr': 0.0003, 'beta2': 0.999, 'epochs': 200, 'batch_size': 64, 'loss': 'clip', 'use_weighting': False, 'max_batches': 1200, 'svd': 0.0, 'negatives': None, 'negative_pool_size': None}, 'clip': {'linear': None, 'twin': True, 'pool': False, 'tmin': None, 'tmax': None, 'tmin_train': None, 'tmax_train': None, 'center': False}, 'test': {'wer_negatives': 10000, 'wer_topx': 10, 'wer_random': False, 'wer_recordings': 40, 'wer_study': None}, 'dset': {'selections': ['gwilliams2022'], 'tmin': -0.5, 'tmax': 2.5, 'n_recordings': 4, 'n_subjects': None, 'n_subjects_test': None, 'shuffle_recordings_seed': -1, 'skip_recordings': 0, 'test_ratio': 0.2, 'valid_ratio': 0.1, 'remove_ratio': 0.0, 'condition': 0.5, 'apply_baseline': True, 'min_block_duration': 6, 'force_uid_assignement': False, 'min_n_blocks_per_split': 1, 'ignore_end_in_block': False, 'ignore_start_in_block': False, 'sample_rate': 120, 'highpass': 0, 'event_mask': True, 'split_wav_as_block': True, 'allow_empty_split': False, 'autoreject': False, 'test': {'tmin': None, 'tmax': None, 'condition': 'word'}, 'features': ['Wav2VecTransformer'], 'extra_test_features': [], 'features_params': {'MelSpectrum': {'n_fft': 512, 'n_mels': 120, 'normalized': True, 'use_log_scale': True, 'log_scale_eps': 1e-05}, 'Pitch': {'min_f0': 100, 'max_f0': 350}, 'WordHash': {'buckets': 100000}, 'XlmEmbedding': {'contextual': False}, 'WordEmbedding': {'lang': 'auto'}, 'WordEmbeddingSmall': {'lang': 'auto'}, 'PartOfSpeech': {'lang': 'auto'}, 'Wav2VecTransformer': {'layers': [14, 15, 16, 17, 18], 'device': 'cpu', 'random': False}, 'Wav2VecChunk': {'device': 'cpu'}}}, 'override_n_subjects_model': None, 'norm': {'scaler': {'per_channel': False, 'n_samples_per_recording': 200, 'n_samples_features': 8000}, 'max_scale': 20.0, 'clip': True, 'exclude_empty_features': False}, 'task': {'type': 'decode', 'meg_init': 0.3, 'lowpass': 0, 'offset_meg_ms': 150, 'lowpass_gt': True, 'lowpass_gt_test': False, 'mask_loss': False}, 'dora': {'dir': './outputs', 'exclude': ['wandb.*', 'num_prints', 'device', 'num_workers', 'verbose', 'cache', 'features_models'], 'git_save': True}, 'model_name': 'simpleconv', 'convrnn': {'concatenate': False, 'depth': 2, 'linear_out': False, 'complex_out': False, 'kernel_size': 4, 'stride': 2, 'growth': 1.0, 'lstm': 4, 'bidirectional_lstm': False, 'flip_lstm': False, 'attention': 0, 'heads': 4, 'conv_dropout': 0.0, 'lstm_dropout': 0.0, 'dropout_input': 0.0, 'batch_norm': False, 'relu_leakiness': 0.0, 'subject_dim': 64, 'embedding_location': ['lstm'], 'embedding_scale': 1.0, 'subject_layers': False, 'subject_layers_dim': 'input'}, 'simpleconv': {'concatenate': False, 'depth': 10, 'linear_out': False, 'complex_out': True, 'kernel_size': 3, 'dilation_growth': 2, 'dilation_period': 5, 'skip': True, 'post_skip': False, 'growth': 1.0, 'scale': None, 'rewrite': False, 'groups': 1, 'glu': 2, 'glu_context': 1, 'glu_glu': True, 'gelu': True, 'dual_path': 0, 'conv_dropout': 0.0, 'dropout_input': 0.0, 'batch_norm': True, 'relu_leakiness': 0.0, 'subject_dim': 0, 'subject_layers': True, 'embedding_scale': 1.0, 'subject_layers_dim': 'input', 'subject_layers_id': False, 'n_fft': None, 'fft_complex': True, 'merger': True, 'merger_pos_dim': 2048, 'merger_channels': 270, 'merger_dropout': 0.2, 'merger_penalty': 0.0, 'merger_per_subject': False, 'dropout': 0.0, 'dropout_rescale': True, 'initial_linear': 270, 'initial_depth': 1, 'initial_nonlin': False, 'hidden': {'meg': 320}}, 'feature_model_name': None, 'selections': {'audio_mous': {'study': 'schoffelen2019', 'modality': 'audio', 'events_filter': None}, 'audio_mous_wl': {'study': 'schoffelen2019', 'modality': 'audio', 'events_filter': 'condition == \"word_list\"'}, 'visual_mous': {'study': 'schoffelen2019', 'modality': 'visual', 'events_filter': None}, 'gwilliams2022': {'study': 'gwilliams2022'}, 'broderick2019': {'study': 'broderick2019'}, 'fake': {'study': 'fake'}, 'brennan2019': {'study': 'brennan2019'}}, 'study_paths': {'default': {'gwilliams2022': './data/gwilliams2022/', 'schoffelen2019': './data/schoffelen2019/', 'brennan2019': './data/brennan2019/', 'broderick2019': './data/broderick2019/'}}}\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m     os\u001b[38;5;241m.\u001b[39mchdir(Path(bm\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__file__\u001b[39m)\u001b[38;5;241m.\u001b[39mparent)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(cfg)\n\u001b[0;32m---> 21\u001b[0m     raw, events \u001b[38;5;241m=\u001b[39m \u001b[43mmeta_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain_nb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# sys.argv = [sys.argv[0]]\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# initialize(config_path=\"conf\")\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# cfg = compose(config_name=\"config.yaml\")\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# raw, events = meta_dataset.main()\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/brainmagick/bm/meta_dataset.py:141\u001b[0m, in \u001b[0;36mmain_nb\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain_nb\u001b[39m(args: tp\u001b[38;5;241m.\u001b[39mAny):\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmain_\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/brainmagick/bm/meta_dataset.py:157\u001b[0m, in \u001b[0;36mmain_\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    155\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCaching intermediate data under \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mcache\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    156\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(args)\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_BM_TEST_PATH\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    161\u001b[0m     main\u001b[38;5;241m.\u001b[39mdora\u001b[38;5;241m.\u001b[39mdir \u001b[38;5;241m=\u001b[39m Path(os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_BM_TEST_PATH\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/projects/brainmagick/bm/meta_dataset.py:133\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    131\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextra_test_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWordHash\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/brainmagick/bm/meta_dataset.py:63\u001b[0m, in \u001b[0;36mget_datasets\u001b[0;34m(selections, n_recordings, test_ratio, valid_ratio, sample_rate, highpass, num_workers, apply_baseline, progress, skip_recordings, min_block_duration, force_uid_assignement, shuffle_recordings_seed, split_assign_seed, min_n_blocks_per_split, features, extra_test_features, test, allow_empty_split, n_subjects, n_subjects_test, remove_ratio, **factory_kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_datasets\u001b[39m(selections: tp\u001b[38;5;241m.\u001b[39mList[tp\u001b[38;5;241m.\u001b[39mDict[\u001b[38;5;28mstr\u001b[39m, tp\u001b[38;5;241m.\u001b[39mAny]],\n\u001b[1;32m     38\u001b[0m         n_recordings: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m     39\u001b[0m         test_ratio: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# get from running gwilliams study\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m     all_recordings \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_recordings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mselections\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_recordings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_recordings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_recordings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle_recordings_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle_recordings_seed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     all_recordings \u001b[38;5;241m=\u001b[39m LogProgress(logger, all_recordings,\n\u001b[1;32m     67\u001b[0m                                       name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreparing cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, level\u001b[38;5;241m=\u001b[39mlogging\u001b[38;5;241m.\u001b[39mDEBUG)\n\u001b[1;32m     68\u001b[0m     all_recordings \u001b[38;5;241m=\u001b[39m [  \u001b[38;5;66;03m# for debugging\u001b[39;00m\n\u001b[1;32m     69\u001b[0m         _preload(s, sample_rate\u001b[38;5;241m=\u001b[39msample_rate, highpass\u001b[38;5;241m=\u001b[39mhighpass) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m all_recordings]\n",
      "File \u001b[0;32m~/projects/brainmagick/bm/dataset.py:391\u001b[0m, in \u001b[0;36m_extract_recordings\u001b[0;34m(selections, n_recordings, skip_recordings, shuffle_recordings_seed)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_extract_recordings\u001b[39m(selections: tp\u001b[38;5;241m.\u001b[39mList[tp\u001b[38;5;241m.\u001b[39mDict[\u001b[38;5;28mstr\u001b[39m, tp\u001b[38;5;241m.\u001b[39mAny]], n_recordings: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m    387\u001b[0m                         skip_recordings: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, shuffle_recordings_seed: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    388\u001b[0m                         ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tp\u001b[38;5;241m.\u001b[39mSequence[studies\u001b[38;5;241m.\u001b[39mRecording]:\n\u001b[1;32m    389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Extract the number of recordings required, and mix audio and visual if need be\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m  \u001b[38;5;66;03m# this is a function to help testing, especially the \"any\" case\u001b[39;00m\n\u001b[0;32m--> 391\u001b[0m     recording_lists \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlist\u001b[39m(studies\u001b[38;5;241m.\u001b[39mfrom_selection(select)) \u001b[38;5;28;01mfor\u001b[39;00m select \u001b[38;5;129;01min\u001b[39;00m selections]\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle_recordings_seed \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# deactivated if -1\u001b[39;00m\n\u001b[1;32m    393\u001b[0m         rng \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mRandomState(seed\u001b[38;5;241m=\u001b[39mshuffle_recordings_seed)\n",
      "File \u001b[0;32m~/projects/brainmagick/bm/dataset.py:391\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_extract_recordings\u001b[39m(selections: tp\u001b[38;5;241m.\u001b[39mList[tp\u001b[38;5;241m.\u001b[39mDict[\u001b[38;5;28mstr\u001b[39m, tp\u001b[38;5;241m.\u001b[39mAny]], n_recordings: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m    387\u001b[0m                         skip_recordings: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, shuffle_recordings_seed: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    388\u001b[0m                         ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tp\u001b[38;5;241m.\u001b[39mSequence[studies\u001b[38;5;241m.\u001b[39mRecording]:\n\u001b[1;32m    389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Extract the number of recordings required, and mix audio and visual if need be\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m  \u001b[38;5;66;03m# this is a function to help testing, especially the \"any\" case\u001b[39;00m\n\u001b[0;32m--> 391\u001b[0m     recording_lists \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstudies\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m select \u001b[38;5;129;01min\u001b[39;00m selections]\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle_recordings_seed \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# deactivated if -1\u001b[39;00m\n\u001b[1;32m    393\u001b[0m         rng \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mRandomState(seed\u001b[38;5;241m=\u001b[39mshuffle_recordings_seed)\n",
      "File \u001b[0;32m~/projects/brainmagick/bm/studies/gwilliams2022.py:63\u001b[0m, in \u001b[0;36mGwilliams2022Recording.iter\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a generator of all recordings\"\"\"\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# download, extract, organize\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# List all recordings: depends on study structure\u001b[39;00m\n\u001b[1;32m     65\u001b[0m paths \u001b[38;5;241m=\u001b[39m StudyPaths()\n",
      "File \u001b[0;32m~/projects/brainmagick/bm/studies/gwilliams2022.py:54\u001b[0m, in \u001b[0;36mGwilliams2022Recording.download\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload\u001b[39m(\u001b[38;5;28mcls\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[43mdownload_osf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mag3kj\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mStudyPaths\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mag3kj\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     download_osf(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh2tzn\u001b[39m\u001b[38;5;124m'\u001b[39m, StudyPaths()\u001b[38;5;241m.\u001b[39mdownload\u001b[38;5;241m.\u001b[39mparent, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mh2tzn\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     56\u001b[0m     download_osf(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mu5327\u001b[39m\u001b[38;5;124m'\u001b[39m, StudyPaths()\u001b[38;5;241m.\u001b[39mdownload\u001b[38;5;241m.\u001b[39mparent, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mu5327\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/projects/brainmagick/bm/studies/download.py:21\u001b[0m, in \u001b[0;36mdownload_osf\u001b[0;34m(study, dset_dir, success)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m dset_dir \u001b[38;5;241m=\u001b[39m to_absolute_path(Path(dset_dir))\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dset_dir\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mexists()\n\u001b[1;32m     22\u001b[0m dl_dir \u001b[38;5;241m=\u001b[39m dset_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdownload\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     24\u001b[0m success_file \u001b[38;5;241m=\u001b[39m dl_dir \u001b[38;5;241m/\u001b[39m success\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import hydra.core.global_hydra\n",
    "import bm\n",
    "from bm import meta_dataset\n",
    "import sys\n",
    "import os\n",
    "from hydra import initialize, initialize_config_module, initialize_config_dir, compose, core\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "from pathlib import Path\n",
    "import inspect\n",
    "\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "\n",
    "with initialize(version_base=\"1.1\", config_path=\"../bm/conf\"):\n",
    "    cfg = compose(config_name=\"config.yaml\")\n",
    "    os.chdir(Path(bm.__file__).parent)\n",
    "    print(cfg)\n",
    "    raw, events = meta_dataset.main_nb(cfg)\n",
    "\n",
    "\n",
    "\n",
    "# sys.argv = [sys.argv[0]]\n",
    "# initialize(config_path=\"conf\")\n",
    "# cfg = compose(config_name=\"config.yaml\")\n",
    "\n",
    "# raw, events = meta_dataset.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainmagick",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
